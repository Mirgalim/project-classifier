import io
import uuid
from pathlib import Path
from typing import Optional, Tuple

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ====== Storage ======
STORAGE_DIR = Path(__file__).parent / "storage"
STORAGE_DIR.mkdir(parents=True, exist_ok=True)

# ====== Error ======
class ClassificationError(Exception):
    pass

REQ_COLS = ["–ï—Ä”©–Ω—Ö–∏–π –∞–Ω–≥–∏–ª–∞–ª", "–¢”©—Ä”©–ª", "–ê–Ω–≥–∏–ª–∞–ª", "–¢–∞–π–ª–±–∞—Ä", "–ë—Ä–µ–Ω–¥", "–°–µ–≥–º–µ–Ω—Ç"]

# ---------- Fast readers ----------
def _read_excel_bytes(file_bytes: bytes, label: str, usecols=None) -> pd.DataFrame:
    try:
        return pd.read_excel(
            io.BytesIO(file_bytes),
            engine="openpyxl",
            dtype=str,
            na_filter=False,
            usecols=usecols
        )
    except Exception as e:
        raise ClassificationError(f"'{label}' —Ñ–∞–π–ª—ã–≥ —É–Ω—à–∏–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π: {e}")

def _read_excel_all_sheets_bytes(file_bytes: bytes, label: str, usecols=None) -> dict[str, pd.DataFrame]:
    try:
        xls = pd.ExcelFile(io.BytesIO(file_bytes), engine="openpyxl")
        return {name: xls.parse(name, dtype=str, na_filter=False, usecols=usecols) for name in xls.sheet_names}
    except Exception as e:
        raise ClassificationError(f"'{label}' Excel-–∏–π–≥ –Ω—ç—ç–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π: {e}")

def _norm(s: pd.Series) -> pd.Series:
    return s.astype(str).str.lower().str.strip().str.replace(r"\s+", " ", regex=True)

def _non_empty(s: pd.Series) -> pd.Series:
    return s.astype(str).str.strip().ne("")

# ======================================================================
# CORE: –≠–Ω–≥–∏–π–Ω TF-IDF + cosine (—Ç–∞–Ω—ã —Ö“Ø—Å—Å—ç–Ω –ª–æ–≥–∏–∫)
# ======================================================================
def _classify_core(
    sales_bytes: bytes,
    category_bytes: bytes,
    manual_bytes: Optional[bytes],
    threshold: float,
) -> Tuple[str, pd.DataFrame]:
    # 1) Sales ‚Äî –∑”©–≤—Ö”©–Ω —Ö—ç—Ä—ç–≥—Ç—ç–π –±–∞–≥–∞–Ω–∞
    sales_df = _read_excel_bytes(sales_bytes, "sales.xlsx", usecols=lambda c: c == "–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä")
    if "–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä" not in sales_df.columns:
        raise ClassificationError("sales.xlsx –¥–æ—Ç–æ—Ä '–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä' –±–∞–≥–∞–Ω–∞ –±–∞–π—Ö —ë—Å—Ç–æ–π!")
    sales_df["–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä"] = _norm(sales_df["–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä"])
    sales_df = sales_df[_non_empty(sales_df["–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä"])].copy()
    products = sales_df["–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä"].unique()

    # 2) Category ‚Äî –±“Ø—Ö sheet, –∑”©–≤—Ö”©–Ω REQ_COLS
    cat_sheets = _read_excel_all_sheets_bytes(category_bytes, "Nomin_ba3.xlsx", usecols=lambda c: c in REQ_COLS[:-1])
    category_df = pd.DataFrame()
    for sheet, df in cat_sheets.items():
        if df is None or df.empty:
            continue
        df = df.copy()
        df["–°–µ–≥–º–µ–Ω—Ç"] = sheet
        for c in REQ_COLS:
            if c not in df.columns:
                df[c] = ""
            df[c] = _norm(df[c])
        category_df = pd.concat([category_df, df[REQ_COLS]], ignore_index=True)

    if category_df.empty:
        raise ClassificationError("–ê–Ω–≥–∏–ª–ª—ã–Ω Excel-–¥ —Ö“Ø—á–∏–Ω—Ç—ç–π –º”©—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π.")

    # 3) –¢“Ø–ª—Ö“Ø“Ø—Ä —Ç–µ–∫—Å—Ç
    category_df["—Ç“Ø–ª—Ö“Ø“Ø—Ä_—Ç–µ–∫—Å—Ç"] = (
        category_df["–¢”©—Ä”©–ª"] + " " +
        category_df["–¢”©—Ä”©–ª"] + " " +
        category_df["–ï—Ä”©–Ω—Ö–∏–π –∞–Ω–≥–∏–ª–∞–ª"] + " " +
        category_df["–ê–Ω–≥–∏–ª–∞–ª"] + " " +
        category_df["–¢–∞–π–ª–±–∞—Ä"] + " " +
        category_df["–ë—Ä–µ–Ω–¥"]
    ).str.strip()

    # —Å—É–ª —Ç“Ø–ª—Ö“Ø“Ø—Ä“Ø“Ø–¥–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç—Ö (2+ “Ø–≥)
    wc = category_df["—Ç“Ø–ª—Ö“Ø“Ø—Ä_—Ç–µ–∫—Å—Ç"].str.replace(r"[^\w\s]+", " ", regex=True).str.split().map(
        lambda x: len(x) if isinstance(x, list) else 0
    )
    category_df = category_df[wc >= 2].reset_index(drop=True)

    # –•—ç—Ä—ç–≤ —Ö–æ–æ—Å–æ–Ω –±–æ–ª default
    if len(products) == 0 or len(category_df) == 0:
        final_result = sales_df.copy()
        for c in ["–ê–Ω–≥–∏–ª–∞–ª", "–¢”©—Ä”©–ª", "–ï—Ä”©–Ω—Ö–∏–π –∞–Ω–≥–∏–ª–∞–ª"]:
            final_result[c] = "UNCLASSIFIED"
        final_result["–°–µ–≥–º–µ–Ω—Ç"] = "‚Äî"
        final_result["–ú–∞–≥–∞–¥–ª–∞–ª"] = np.float32(0.0)
        return uuid.uuid4().hex[:12], final_result

    # 4) TF-IDF + cosine
    texts = list(products) + list(category_df["—Ç“Ø–ª—Ö“Ø“Ø—Ä_—Ç–µ–∫—Å—Ç"].values)
    vectorizer = TfidfVectorizer(lowercase=False)  # –¥–æ–æ—Ä–æ–æ lowercase —Ö–∏–π—á–∏—Ö—Å—ç–Ω
    tfidf = vectorizer.fit_transform(texts)
    prod_vecs = tfidf[:len(products)]
    cat_vecs  = tfidf[len(products):]
    sim = cosine_similarity(prod_vecs, cat_vecs)

    # 5) –û–Ω–æ–æ–ª—Ç
    idx = sim.argmax(axis=1)
    sc  = sim.max(axis=1).astype(np.float32)
    classified = pd.DataFrame({
        "–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä": products,
        "–ê–Ω–≥–∏–ª–∞–ª": category_df.iloc[idx]["–ê–Ω–≥–∏–ª–∞–ª"].to_numpy(),
        "–¢”©—Ä”©–ª": category_df.iloc[idx]["–¢”©—Ä”©–ª"].to_numpy(),
        "–ï—Ä”©–Ω—Ö–∏–π –∞–Ω–≥–∏–ª–∞–ª": category_df.iloc[idx]["–ï—Ä”©–Ω—Ö–∏–π –∞–Ω–≥–∏–ª–∞–ª"].to_numpy(),
        "–°–µ–≥–º–µ–Ω—Ç": category_df.iloc[idx]["–°–µ–≥–º–µ–Ω—Ç"].to_numpy(),
        "–ú–∞–≥–∞–¥–ª–∞–ª": sc,
    })

    # 6) Manual override (—Å–æ–Ω–≥–æ–ª—Ç)
    if manual_bytes is not None:
        manual = _read_excel_bytes(manual_bytes, "manual_fix.xlsx")
        if "–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä" not in manual.columns:
            raise ClassificationError("manual_fix.xlsx –¥–æ—Ç–æ—Ä '–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä' –±–∞–≥–∞–Ω–∞ –±–∞–π—Ö —ë—Å—Ç–æ–π!")
        manual["–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä"] = _norm(manual["–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä"])
        classified = classified.merge(manual, on="–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä", how="left", suffixes=("", "_–≥–∞—Ä"))

        low = classified["–ú–∞–≥–∞–¥–ª–∞–ª"] < threshold

        def override(col: str):
            g = f"{col}_–≥–∞—Ä"
            if g in classified.columns:
                mask = low & classified[g].astype(str).str.strip().ne("")
                classified.loc[mask, col] = classified.loc[mask, g]

        for c in ["–ê–Ω–≥–∏–ª–∞–ª", "–¢”©—Ä”©–ª", "–ï—Ä”©–Ω—Ö–∏–π –∞–Ω–≥–∏–ª–∞–ª", "–°–µ–≥–º–µ–Ω—Ç"]:
            override(c)

        classified = classified.drop(columns=[c for c in classified.columns if c.endswith("_–≥–∞—Ä")], errors="ignore")

    # 7) –ë—É—Ü–∞–∞–∂ —Ç–∞—Ä–∞–∞—Ö + NaN-–≥“Ø–π
    final_result = sales_df.merge(classified, on="–ë–∞—Ä–∞–∞–Ω—ã –Ω—ç—Ä", how="left").fillna("")
    return uuid.uuid4().hex[:12], final_result

# ======================================================================
# PUBLIC API
# ======================================================================
def run_classification(
    sales_bytes: bytes,
    category_bytes: bytes,
    manual_bytes: Optional[bytes] = None,
    probability_threshold: float = 0.15,
    batch_size: int = 2000,    # signature —Ö–∞–¥–≥–∞–ª–∂ “Ø–ª–¥—ç—ç–≤
    max_features: int = 10000, # signature —Ö–∞–¥–≥–∞–ª–∂ “Ø–ª–¥—ç—ç–≤
    engine: str = "script",
) -> Tuple[str, pd.DataFrame]:
    return _classify_core(
        sales_bytes=sales_bytes,
        category_bytes=category_bytes,
        manual_bytes=manual_bytes,
        threshold=probability_threshold,
    )

def save_excel_file(df: pd.DataFrame, job_id: str) -> Path:
    out_path = STORAGE_DIR / f"angilsan_{job_id}.xlsx"
    df = df.fillna("")
    with pd.ExcelWriter(out_path, engine="openpyxl") as w:   # üëà engine-–≥ —Å–æ–ª—å—Å–æ–Ω
        df.to_excel(w, index=False, sheet_name="Results")
    return out_path

